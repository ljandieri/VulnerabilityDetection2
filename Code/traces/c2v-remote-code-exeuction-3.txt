C:\Python39\python.exe D:/VulnerabilityDetection3/Code/c2v_makemodel.py
finished loading.  13:39
cutoff 67255
cutoff2 81666
Creating training dataset... (remote_code_execution)
Creating validation dataset...
Creating finaltest dataset...
Train length: 67255
Test length: 14411
Finaltesting length: 14412
time:  13:42
D:\VulnerabilityDetection3\Code\c2v_makemodel.py:255: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X_train =  numpy.array(TrainX)
D:\VulnerabilityDetection3\Code\c2v_makemodel.py:261: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X_test =  numpy.array(ValidateX)
D:\VulnerabilityDetection3\Code\c2v_makemodel.py:263: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X_finaltest =  numpy.array(FinaltestX)
numpy array done.  13:42
67255 samples in the training set.
14411 samples in the validation set.
14412 samples in the final test set.
percentage of vulnerable samples: 8.94%
absolute amount of vulnerable samples in test set: 1240
Starting LSTM:  13:42
Dropout: 0.2
Neurons: 70
Optimizer: adam
Epochs: 100
Batch Size: 128
max length: 200
2022-03-08 13:43:36.747458: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-08 13:43:38.330287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3969 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5
Compiled LSTM:  13:43
2022-03-08 13:43:45.211818: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1076080000 exceeds 10% of free system memory.
Epoch 1/100
2022-03-08 13:43:49.649953: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200
526/526 [==============================] - 11s 12ms/step - loss: 0.8326 - f1: 0.1606
Epoch 2/100
526/526 [==============================] - 7s 13ms/step - loss: 0.8314 - f1: 0.1636
Epoch 3/100
526/526 [==============================] - 7s 13ms/step - loss: 0.8309 - f1: 0.1647
Epoch 4/100
526/526 [==============================] - 6s 12ms/step - loss: 0.8292 - f1: 0.1663
Epoch 5/100
526/526 [==============================] - 7s 13ms/step - loss: 0.8247 - f1: 0.1699
Epoch 6/100
526/526 [==============================] - 6s 12ms/step - loss: 0.8204 - f1: 0.1746
Epoch 7/100
526/526 [==============================] - 6s 12ms/step - loss: 0.8226 - f1: 0.1715
Epoch 8/100
526/526 [==============================] - 7s 12ms/step - loss: 0.8201 - f1: 0.1744
Epoch 9/100
526/526 [==============================] - 7s 13ms/step - loss: 0.7906 - f1: 0.2051
Epoch 10/100
526/526 [==============================] - 6s 12ms/step - loss: 0.7531 - f1: 0.2444
Epoch 11/100
526/526 [==============================] - 7s 13ms/step - loss: 0.7077 - f1: 0.2913
Epoch 12/100
526/526 [==============================] - 7s 13ms/step - loss: 0.6749 - f1: 0.3244
Epoch 13/100
526/526 [==============================] - 7s 13ms/step - loss: 0.6354 - f1: 0.3654
Epoch 14/100
526/526 [==============================] - 7s 13ms/step - loss: 0.6501 - f1: 0.3467
Epoch 15/100
526/526 [==============================] - 7s 13ms/step - loss: 0.5974 - f1: 0.4016
Epoch 16/100
526/526 [==============================] - 6s 12ms/step - loss: 0.6381 - f1: 0.3601
Epoch 17/100
526/526 [==============================] - 6s 12ms/step - loss: 0.5925 - f1: 0.4051
Epoch 18/100
526/526 [==============================] - 6s 12ms/step - loss: 0.5751 - f1: 0.4263
Epoch 19/100
526/526 [==============================] - 7s 12ms/step - loss: 0.5513 - f1: 0.4456
Epoch 20/100
526/526 [==============================] - 7s 13ms/step - loss: 0.5419 - f1: 0.4554
Epoch 21/100
526/526 [==============================] - 7s 13ms/step - loss: 0.5199 - f1: 0.4797
Epoch 22/100
526/526 [==============================] - 6s 12ms/step - loss: 0.4941 - f1: 0.5039
Epoch 23/100
526/526 [==============================] - 6s 12ms/step - loss: 0.5042 - f1: 0.4930
Epoch 24/100
526/526 [==============================] - 6s 12ms/step - loss: 0.4618 - f1: 0.5381
Epoch 25/100
526/526 [==============================] - 6s 12ms/step - loss: 0.4702 - f1: 0.5293
Epoch 26/100
526/526 [==============================] - 7s 13ms/step - loss: 0.4814 - f1: 0.5168
Epoch 27/100
526/526 [==============================] - 7s 13ms/step - loss: 0.4965 - f1: 0.5007
Epoch 28/100
526/526 [==============================] - 6s 12ms/step - loss: 0.4947 - f1: 0.5028
Epoch 29/100
526/526 [==============================] - 7s 13ms/step - loss: 0.4536 - f1: 0.5465
Epoch 30/100
526/526 [==============================] - 7s 13ms/step - loss: 0.4277 - f1: 0.5719
Epoch 31/100
526/526 [==============================] - 7s 13ms/step - loss: 0.4211 - f1: 0.5771
Epoch 32/100
526/526 [==============================] - 7s 13ms/step - loss: 0.4129 - f1: 0.5862
Epoch 33/100
526/526 [==============================] - 7s 12ms/step - loss: 0.3937 - f1: 0.6057
Epoch 34/100
526/526 [==============================] - 6s 12ms/step - loss: 0.4017 - f1: 0.5967
Epoch 35/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3938 - f1: 0.6064
Epoch 36/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3895 - f1: 0.6089
Epoch 37/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3969 - f1: 0.6042
Epoch 38/100
526/526 [==============================] - 7s 13ms/step - loss: 0.4498 - f1: 0.5473
Epoch 39/100
526/526 [==============================] - 6s 12ms/step - loss: 0.4829 - f1: 0.5129
Epoch 40/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3929 - f1: 0.6048
Epoch 41/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3622 - f1: 0.6371
Epoch 42/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3620 - f1: 0.6368
Epoch 43/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3492 - f1: 0.6507
Epoch 44/100
526/526 [==============================] - 7s 12ms/step - loss: 0.3537 - f1: 0.6464
Epoch 45/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3377 - f1: 0.6623
Epoch 46/100
526/526 [==============================] - 7s 12ms/step - loss: 0.3495 - f1: 0.6469
Epoch 47/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3742 - f1: 0.6247
Epoch 48/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3487 - f1: 0.6493
Epoch 49/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3319 - f1: 0.6653
Epoch 50/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3359 - f1: 0.6635
Epoch 51/100
526/526 [==============================] - 7s 12ms/step - loss: 0.3407 - f1: 0.6578
Epoch 52/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3290 - f1: 0.6706
Epoch 53/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3166 - f1: 0.6846
Epoch 54/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3177 - f1: 0.6820
Epoch 55/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3451 - f1: 0.6535
Epoch 56/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3176 - f1: 0.6812
Epoch 57/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3340 - f1: 0.6651
Epoch 58/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3285 - f1: 0.6704
Epoch 59/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2943 - f1: 0.7077
Epoch 60/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2840 - f1: 0.7171
Epoch 61/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3022 - f1: 0.6953
Epoch 62/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3148 - f1: 0.6850
Epoch 63/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2938 - f1: 0.7053
Epoch 64/100
526/526 [==============================] - 7s 12ms/step - loss: 0.2853 - f1: 0.7161
Epoch 65/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3371 - f1: 0.6612
Epoch 66/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3500 - f1: 0.6478
Epoch 67/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2861 - f1: 0.7153
Epoch 68/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2666 - f1: 0.7340
Epoch 69/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2806 - f1: 0.7188
Epoch 70/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2656 - f1: 0.7343
Epoch 71/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2618 - f1: 0.7390
Epoch 72/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2643 - f1: 0.7349
Epoch 73/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2765 - f1: 0.7237
Epoch 74/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2783 - f1: 0.7212
Epoch 75/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2569 - f1: 0.7418
Epoch 76/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2803 - f1: 0.7213
Epoch 77/100
526/526 [==============================] - 7s 14ms/step - loss: 0.2604 - f1: 0.7395
Epoch 78/100
526/526 [==============================] - 7s 14ms/step - loss: 0.7661 - f1: 0.2279
Epoch 79/100
526/526 [==============================] - 7s 13ms/step - loss: 0.4258 - f1: 0.5762
Epoch 80/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2980 - f1: 0.6996
Epoch 81/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2763 - f1: 0.7221
Epoch 82/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2604 - f1: 0.7382
Epoch 83/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2513 - f1: 0.7483
Epoch 84/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2439 - f1: 0.7572
Epoch 85/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2493 - f1: 0.7502
Epoch 86/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2697 - f1: 0.7292
Epoch 87/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2582 - f1: 0.7397
Epoch 88/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2671 - f1: 0.7323
Epoch 89/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2474 - f1: 0.7553
Epoch 90/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2447 - f1: 0.7522
Epoch 91/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2314 - f1: 0.7690
Epoch 92/100
526/526 [==============================] - 7s 12ms/step - loss: 0.2417 - f1: 0.7574
Epoch 93/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2495 - f1: 0.7505
Epoch 94/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2347 - f1: 0.7672
Epoch 95/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2543 - f1: 0.7441
Epoch 96/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2449 - f1: 0.7538
Epoch 97/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2852 - f1: 0.7126
Epoch 98/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3404 - f1: 0.6596
Epoch 99/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2330 - f1: 0.7667
Epoch 100/100
526/526 [==============================] - 7s 12ms/step - loss: 0.2562 - f1: 0.7434
Now predicting on train set (0.2 dropout)
Accuracy: 0.9703516467177161
Precision: 0.8890177880897139
Recall: 0.7640412097042206
F1 score: 0.821805


Now predicting on test set (0.2 dropout)
Accuracy: 0.9666921101936021
Precision: 0.8696498054474708
Recall: 0.7209677419354839
F1 score: 0.788360


Now predicting on finaltest set (0.2 dropout)
Accuracy: 0.9641965029142381
Precision: 0.8712328767123287
Recall: 0.7178329571106095
F1 score: 0.787129


saving LSTM model remote_code_execution.  13:55



