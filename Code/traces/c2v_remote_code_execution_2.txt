C:\Python39\python.exe D:/VulnerabilityDetection3/Code/c2v_makemodel.py
finished loading.  11:47
cutoff 67255
cutoff2 81666
Creating training dataset... (remote_code_execution)
Creating validation dataset...
Creating finaltest dataset...
Train length: 67255
Test length: 14411
Finaltesting length: 14412
time:  11:50
D:\VulnerabilityDetection3\Code\c2v_makemodel.py:255: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X_train =  numpy.array(TrainX)
D:\VulnerabilityDetection3\Code\c2v_makemodel.py:261: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X_test =  numpy.array(ValidateX)
D:\VulnerabilityDetection3\Code\c2v_makemodel.py:263: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X_finaltest =  numpy.array(FinaltestX)
numpy array done.  11:50
67255 samples in the training set.
14411 samples in the validation set.
14412 samples in the final test set.
percentage of vulnerable samples: 8.95%
absolute amount of vulnerable samples in test set: 1302
Starting LSTM:  11:50
Dropout: 0.2
Neurons: 100
Optimizer: adam
Epochs: 50
Batch Size: 128
max length: 200
2022-03-08 11:51:27.204536: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-08 11:51:28.211440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3969 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5
Compiled LSTM:  11:51
2022-03-08 11:51:33.304060: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1076080000 exceeds 10% of free system memory.
Epoch 1/50
2022-03-08 11:51:37.818383: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200
526/526 [==============================] - 11s 14ms/step - loss: 0.8338 - f1: 0.1609
Epoch 2/50
526/526 [==============================] - 7s 14ms/step - loss: 0.8311 - f1: 0.1631
Epoch 3/50
526/526 [==============================] - 7s 14ms/step - loss: 0.8309 - f1: 0.1635
Epoch 4/50
526/526 [==============================] - 7s 14ms/step - loss: 0.8193 - f1: 0.1811
Epoch 5/50
526/526 [==============================] - 8s 14ms/step - loss: 0.7644 - f1: 0.2310
Epoch 6/50
526/526 [==============================] - 8s 15ms/step - loss: 0.7555 - f1: 0.2398
Epoch 7/50
526/526 [==============================] - 8s 14ms/step - loss: 0.7495 - f1: 0.2479
Epoch 8/50
526/526 [==============================] - 7s 14ms/step - loss: 0.7100 - f1: 0.2849
Epoch 9/50
526/526 [==============================] - 7s 14ms/step - loss: 0.6943 - f1: 0.3028
Epoch 10/50
526/526 [==============================] - 7s 14ms/step - loss: 0.6745 - f1: 0.3220
Epoch 11/50
526/526 [==============================] - 7s 14ms/step - loss: 0.6676 - f1: 0.3289
Epoch 12/50
526/526 [==============================] - 7s 14ms/step - loss: 0.6506 - f1: 0.3469
Epoch 13/50
526/526 [==============================] - 7s 14ms/step - loss: 0.6367 - f1: 0.3586
Epoch 14/50
526/526 [==============================] - 7s 14ms/step - loss: 0.6086 - f1: 0.3879
Epoch 15/50
526/526 [==============================] - 7s 14ms/step - loss: 0.5869 - f1: 0.4122
Epoch 16/50
526/526 [==============================] - 7s 14ms/step - loss: 0.5716 - f1: 0.4238
Epoch 17/50
526/526 [==============================] - 7s 14ms/step - loss: 0.5528 - f1: 0.4461
Epoch 18/50
526/526 [==============================] - 7s 14ms/step - loss: 0.5230 - f1: 0.4751
Epoch 19/50
526/526 [==============================] - 7s 14ms/step - loss: 0.5295 - f1: 0.4667
Epoch 20/50
526/526 [==============================] - 7s 13ms/step - loss: 0.5081 - f1: 0.4889
Epoch 21/50
526/526 [==============================] - 7s 14ms/step - loss: 0.4732 - f1: 0.5279
Epoch 22/50
526/526 [==============================] - 7s 14ms/step - loss: 0.4714 - f1: 0.5267
Epoch 23/50
526/526 [==============================] - 7s 14ms/step - loss: 0.4748 - f1: 0.5207
Epoch 24/50
526/526 [==============================] - 7s 14ms/step - loss: 0.4553 - f1: 0.5439
Epoch 25/50
526/526 [==============================] - 7s 14ms/step - loss: 0.4305 - f1: 0.5679
Epoch 26/50
526/526 [==============================] - 7s 13ms/step - loss: 0.4222 - f1: 0.5770
Epoch 27/50
526/526 [==============================] - 7s 13ms/step - loss: 0.4306 - f1: 0.5673
Epoch 28/50
526/526 [==============================] - 7s 13ms/step - loss: 0.4028 - f1: 0.5952
Epoch 29/50
526/526 [==============================] - 7s 14ms/step - loss: 0.3978 - f1: 0.6029
Epoch 30/50
526/526 [==============================] - 8s 16ms/step - loss: 0.4070 - f1: 0.5919
Epoch 31/50
526/526 [==============================] - 9s 17ms/step - loss: 0.3802 - f1: 0.6192
Epoch 32/50
526/526 [==============================] - 9s 16ms/step - loss: 0.3822 - f1: 0.6179
Epoch 33/50
526/526 [==============================] - 8s 15ms/step - loss: 0.3728 - f1: 0.6269
Epoch 34/50
526/526 [==============================] - 7s 14ms/step - loss: 0.3767 - f1: 0.6205
Epoch 35/50
526/526 [==============================] - 8s 15ms/step - loss: 0.3576 - f1: 0.6407
Epoch 36/50
526/526 [==============================] - 7s 14ms/step - loss: 0.3523 - f1: 0.6449
Epoch 37/50
526/526 [==============================] - 7s 14ms/step - loss: 0.3473 - f1: 0.6516
Epoch 38/50
526/526 [==============================] - 7s 14ms/step - loss: 0.3373 - f1: 0.6604
Epoch 39/50
526/526 [==============================] - 7s 13ms/step - loss: 0.3449 - f1: 0.6553
Epoch 40/50
526/526 [==============================] - 7s 13ms/step - loss: 0.3167 - f1: 0.6816
Epoch 41/50
526/526 [==============================] - 7s 13ms/step - loss: 0.3075 - f1: 0.6921
Epoch 42/50
526/526 [==============================] - 7s 14ms/step - loss: 0.2990 - f1: 0.7005
Epoch 43/50
526/526 [==============================] - 7s 13ms/step - loss: 0.3002 - f1: 0.6996
Epoch 44/50
526/526 [==============================] - 7s 13ms/step - loss: 0.2956 - f1: 0.7033
Epoch 45/50
526/526 [==============================] - 7s 13ms/step - loss: 0.2936 - f1: 0.7062
Epoch 46/50
526/526 [==============================] - 7s 13ms/step - loss: 0.2829 - f1: 0.7170
Epoch 47/50
526/526 [==============================] - 7s 14ms/step - loss: 0.2817 - f1: 0.7188
Epoch 48/50
526/526 [==============================] - 7s 14ms/step - loss: 0.2823 - f1: 0.7170
Epoch 49/50
526/526 [==============================] - 7s 14ms/step - loss: 0.2770 - f1: 0.7217
Epoch 50/50
526/526 [==============================] - 7s 13ms/step - loss: 0.2661 - f1: 0.7323
Now predicting on train set (0.2 dropout)
Accuracy: 0.9651773102371571
Precision: 0.8839974963488421
Recall: 0.7034700315457413
F1 score: 0.783469


Now predicting on test set (0.2 dropout)
Accuracy: 0.9639164527097356
Precision: 0.8781431334622823
Recall: 0.6973886328725039
F1 score: 0.777397


Now predicting on finaltest set (0.2 dropout)
Accuracy: 0.9645434360255343
Precision: 0.8751248751248751
Recall: 0.694136291600634
F1 score: 0.774194


saving LSTM model remote_code_execution.  11:57



