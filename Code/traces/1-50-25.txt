C:\Python39\python.exe D:/VulnerabilityDetection3/Code/c2v_makemodel.py
finished loading.  14:35
cutoff 67255
cutoff2 81666
Creating training dataset... (remote_code_execution)
Creating validation dataset...
Creating finaltest dataset...
Train length: 67255
Test length: 14411
Finaltesting length: 14412
time:  14:40
D:\VulnerabilityDetection3\Code\c2v_makemodel.py:255: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X_train =  numpy.array(TrainX)
D:\VulnerabilityDetection3\Code\c2v_makemodel.py:261: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X_test =  numpy.array(ValidateX)
D:\VulnerabilityDetection3\Code\c2v_makemodel.py:263: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X_finaltest =  numpy.array(FinaltestX)
numpy array done.  14:40
67255 samples in the training set.
14411 samples in the validation set.
14412 samples in the final test set.
percentage of vulnerable samples: 9.08%
absolute amount of vulnerable samples in test set: 1234
Starting LSTM:  14:40
Dropout: 0.2
Neurons: 70
Optimizer: adam
Epochs: 100
Batch Size: 128
max length: 200
2022-03-09 14:41:45.050800: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-09 14:41:46.175550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3969 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5
Compiled LSTM:  14:41
2022-03-09 14:41:54.653119: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1345100000 exceeds 10% of free system memory.
Epoch 1/100
2022-03-09 14:41:59.241125: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200
526/526 [==============================] - 11s 13ms/step - loss: 0.8285 - f1: 0.1668
Epoch 2/100
526/526 [==============================] - 7s 13ms/step - loss: 0.8304 - f1: 0.1633
Epoch 3/100
526/526 [==============================] - 6s 12ms/step - loss: 0.8235 - f1: 0.1719
Epoch 4/100
526/526 [==============================] - 6s 12ms/step - loss: 0.8126 - f1: 0.1862
Epoch 5/100
526/526 [==============================] - 6s 12ms/step - loss: 0.7858 - f1: 0.2119
Epoch 6/100
526/526 [==============================] - 6s 12ms/step - loss: 0.7716 - f1: 0.2245
Epoch 7/100
526/526 [==============================] - 7s 13ms/step - loss: 0.7592 - f1: 0.2366
Epoch 8/100
526/526 [==============================] - 7s 13ms/step - loss: 0.7377 - f1: 0.2600
Epoch 9/100
526/526 [==============================] - 7s 13ms/step - loss: 0.7208 - f1: 0.2750
Epoch 10/100
526/526 [==============================] - 7s 13ms/step - loss: 0.7702 - f1: 0.2278
Epoch 11/100
526/526 [==============================] - 7s 12ms/step - loss: 0.6616 - f1: 0.3379
Epoch 12/100
526/526 [==============================] - 7s 12ms/step - loss: 0.6213 - f1: 0.3740
Epoch 13/100
526/526 [==============================] - 7s 12ms/step - loss: 0.5976 - f1: 0.3982
Epoch 14/100
526/526 [==============================] - 6s 12ms/step - loss: 0.5496 - f1: 0.4485
Epoch 15/100
526/526 [==============================] - 7s 12ms/step - loss: 0.5203 - f1: 0.4793
Epoch 16/100
526/526 [==============================] - 7s 13ms/step - loss: 0.4892 - f1: 0.5106
Epoch 17/100
526/526 [==============================] - 7s 13ms/step - loss: 0.4577 - f1: 0.5421
Epoch 18/100
526/526 [==============================] - 7s 12ms/step - loss: 0.4365 - f1: 0.5624
Epoch 19/100
526/526 [==============================] - 7s 13ms/step - loss: 0.4174 - f1: 0.5833
Epoch 20/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3923 - f1: 0.6074
Epoch 21/100
526/526 [==============================] - 7s 12ms/step - loss: 0.3809 - f1: 0.6193
Epoch 22/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3566 - f1: 0.6440
Epoch 23/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3773 - f1: 0.6206
Epoch 24/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3877 - f1: 0.6104
Epoch 25/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3462 - f1: 0.6532
Epoch 26/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3366 - f1: 0.6628
Epoch 27/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3333 - f1: 0.6668
Epoch 28/100
526/526 [==============================] - 7s 12ms/step - loss: 0.3279 - f1: 0.6713
Epoch 29/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3244 - f1: 0.6729
Epoch 30/100
526/526 [==============================] - 6s 12ms/step - loss: 0.3097 - f1: 0.6900
Epoch 31/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3059 - f1: 0.6952
Epoch 32/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3092 - f1: 0.6915
Epoch 33/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2936 - f1: 0.7074
Epoch 34/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2959 - f1: 0.7015
Epoch 35/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2875 - f1: 0.7101
Epoch 36/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2780 - f1: 0.7209
Epoch 37/100
526/526 [==============================] - 7s 12ms/step - loss: 0.2855 - f1: 0.7122
Epoch 38/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2748 - f1: 0.7249
Epoch 39/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2666 - f1: 0.7349
Epoch 40/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2621 - f1: 0.7374
Epoch 41/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2638 - f1: 0.7344
Epoch 42/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2525 - f1: 0.7478
Epoch 43/100
526/526 [==============================] - 7s 13ms/step - loss: 0.3201 - f1: 0.6785
Epoch 44/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2658 - f1: 0.7330
Epoch 45/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2608 - f1: 0.7367
Epoch 46/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2598 - f1: 0.7403
Epoch 47/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2491 - f1: 0.7490
Epoch 48/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2413 - f1: 0.7577
Epoch 49/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2468 - f1: 0.7532
Epoch 50/100
526/526 [==============================] - 7s 12ms/step - loss: 0.2380 - f1: 0.7617
Epoch 51/100
526/526 [==============================] - 7s 12ms/step - loss: 0.2374 - f1: 0.7618
Epoch 52/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2418 - f1: 0.7576
Epoch 53/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2477 - f1: 0.7505
Epoch 54/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2456 - f1: 0.7540
Epoch 55/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2422 - f1: 0.7567
Epoch 56/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2348 - f1: 0.7642
Epoch 57/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2579 - f1: 0.7406
Epoch 58/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2400 - f1: 0.7591
Epoch 59/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2342 - f1: 0.7642
Epoch 60/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2332 - f1: 0.7669
Epoch 61/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2417 - f1: 0.7553
Epoch 62/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2296 - f1: 0.7723
Epoch 63/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2362 - f1: 0.7648
Epoch 64/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2387 - f1: 0.7590
Epoch 65/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2703 - f1: 0.7284
Epoch 66/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2386 - f1: 0.7615
Epoch 67/100
526/526 [==============================] - 7s 12ms/step - loss: 0.2272 - f1: 0.7723
Epoch 68/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2353 - f1: 0.7621
Epoch 69/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2185 - f1: 0.7819
Epoch 70/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2235 - f1: 0.7760
Epoch 71/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2590 - f1: 0.7405
Epoch 72/100
526/526 [==============================] - 7s 12ms/step - loss: 0.2259 - f1: 0.7743
Epoch 73/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2273 - f1: 0.7722
Epoch 74/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2221 - f1: 0.7764
Epoch 75/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2317 - f1: 0.7645
Epoch 76/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2073 - f1: 0.7929
Epoch 77/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2036 - f1: 0.7964
Epoch 78/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2145 - f1: 0.7837
Epoch 79/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2352 - f1: 0.7618
Epoch 80/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2195 - f1: 0.7790
Epoch 81/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2165 - f1: 0.7833
Epoch 82/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2153 - f1: 0.7834
Epoch 83/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2165 - f1: 0.7813
Epoch 84/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2171 - f1: 0.7800
Epoch 85/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2168 - f1: 0.7827
Epoch 86/100
526/526 [==============================] - 7s 12ms/step - loss: 0.2069 - f1: 0.7924
Epoch 87/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2027 - f1: 0.7970
Epoch 88/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2103 - f1: 0.7886
Epoch 89/100
526/526 [==============================] - 7s 13ms/step - loss: 0.1906 - f1: 0.8084
Epoch 90/100
526/526 [==============================] - 7s 12ms/step - loss: 0.2033 - f1: 0.7959
Epoch 91/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2070 - f1: 0.7930
Epoch 92/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2082 - f1: 0.7911
Epoch 93/100
526/526 [==============================] - 7s 13ms/step - loss: 0.1869 - f1: 0.8137
Epoch 94/100
526/526 [==============================] - 7s 13ms/step - loss: 0.1989 - f1: 0.8002
Epoch 95/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2041 - f1: 0.7949
Epoch 96/100
526/526 [==============================] - 6s 12ms/step - loss: 0.2018 - f1: 0.7969
Epoch 97/100
526/526 [==============================] - 7s 13ms/step - loss: 0.1879 - f1: 0.8102
Epoch 98/100
526/526 [==============================] - 6s 12ms/step - loss: 0.1868 - f1: 0.8131
Epoch 99/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2031 - f1: 0.7958
Epoch 100/100
526/526 [==============================] - 7s 13ms/step - loss: 0.2006 - f1: 0.7987
Now predicting on train set (0.2 dropout)
Accuracy: 0.9743216117760761
Precision: 0.9167142042213349
Recall: 0.7890343698854337
F1 score: 0.848096


Now predicting on test set (0.2 dropout)
Accuracy: 0.9723822080355284
Precision: 0.8913857677902621
Recall: 0.7714748784440842
F1 score: 0.827107


Now predicting on finaltest set (0.2 dropout)
Accuracy: 0.9704412989175687
Precision: 0.8835680751173709
Recall: 0.7570394207562349
F1 score: 0.815425


saving LSTM model remote_code_execution.  14:53



