C:\Python39\python.exe D:/VulnerabilityDetection3/Code/c2v_makemodel.py
finished loading.  14:59
cutoff 67255
cutoff2 81666
Creating training dataset... (remote_code_execution)
Creating validation dataset...
Creating finaltest dataset...
Train length: 67255
Test length: 14411
Finaltesting length: 14412
time:  15:04
D:\VulnerabilityDetection3\Code\c2v_makemodel.py:255: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X_train =  numpy.array(TrainX)
D:\VulnerabilityDetection3\Code\c2v_makemodel.py:261: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X_test =  numpy.array(ValidateX)
D:\VulnerabilityDetection3\Code\c2v_makemodel.py:263: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  X_finaltest =  numpy.array(FinaltestX)
numpy array done.  15:04
67255 samples in the training set.
14411 samples in the validation set.
14412 samples in the final test set.
percentage of vulnerable samples: 8.95%
absolute amount of vulnerable samples in test set: 1254
Starting LSTM:  15:04
Dropout: 0.2
Neurons: 70
Optimizer: adam
Epochs: 50
Batch Size: 64
max length: 200
2022-03-08 15:06:35.374258: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-08 15:06:36.253941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3969 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5
Compiled LSTM:  15:06
2022-03-08 15:06:46.739621: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1345100000 exceeds 10% of free system memory.
Epoch 1/50
2022-03-08 15:06:50.848186: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200
1051/1051 [==============================] - 15s 11ms/step - loss: 0.8273 - f1: 0.1619
Epoch 2/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.8267 - f1: 0.1618
Epoch 3/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.8252 - f1: 0.1651
Epoch 4/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.8267 - f1: 0.1626
Epoch 5/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.8241 - f1: 0.1658
Epoch 6/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.8265 - f1: 0.1626
Epoch 7/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.8119 - f1: 0.1783
Epoch 8/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.7472 - f1: 0.2425
Epoch 9/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.8211 - f1: 0.1672
Epoch 10/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.8236 - f1: 0.1654
Epoch 11/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.7659 - f1: 0.2244
Epoch 12/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.6878 - f1: 0.3030
Epoch 13/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.6919 - f1: 0.2973
Epoch 14/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.6471 - f1: 0.3424
Epoch 15/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.6163 - f1: 0.3725
Epoch 16/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.5950 - f1: 0.3961
Epoch 17/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.5786 - f1: 0.4112
Epoch 18/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.5484 - f1: 0.4431
Epoch 19/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.5266 - f1: 0.4639
Epoch 20/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.5256 - f1: 0.4646
Epoch 21/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.4984 - f1: 0.4938
Epoch 22/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.4999 - f1: 0.4919
Epoch 23/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.4942 - f1: 0.4972
Epoch 24/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.4631 - f1: 0.5290
Epoch 25/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.4573 - f1: 0.5335
Epoch 26/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.4474 - f1: 0.5436
Epoch 27/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.4243 - f1: 0.5675
Epoch 28/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.4170 - f1: 0.5738
Epoch 29/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.4057 - f1: 0.5853
Epoch 30/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.3828 - f1: 0.6113
Epoch 31/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.3848 - f1: 0.6101
Epoch 32/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.3868 - f1: 0.6039
Epoch 33/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.3730 - f1: 0.6234
Epoch 34/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.3744 - f1: 0.6211
Epoch 35/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.3546 - f1: 0.6395
Epoch 36/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.3523 - f1: 0.6426
Epoch 37/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.3753 - f1: 0.6178
Epoch 38/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.3434 - f1: 0.6522
Epoch 39/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.3389 - f1: 0.6568
Epoch 40/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.3460 - f1: 0.6494
Epoch 41/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.3547 - f1: 0.6380
Epoch 42/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.3278 - f1: 0.6670
Epoch 43/50
1051/1051 [==============================] - 11s 11ms/step - loss: 0.3506 - f1: 0.6409
Epoch 44/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.3298 - f1: 0.6634
Epoch 45/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.3218 - f1: 0.6732
Epoch 46/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.3230 - f1: 0.6705
Epoch 47/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.3110 - f1: 0.6849
Epoch 48/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.3213 - f1: 0.6731
Epoch 49/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.3284 - f1: 0.6645
Epoch 50/50
1051/1051 [==============================] - 12s 11ms/step - loss: 0.3040 - f1: 0.6914
Now predicting on train set (0.2 dropout)
Accuracy: 0.9620846033752137
Precision: 0.8597181931205967
Recall: 0.6889737628694785
F1 score: 0.764934


Now predicting on test set (0.2 dropout)
Accuracy: 0.9589202692387759
Precision: 0.8264299802761341
Recall: 0.6682615629984051
F1 score: 0.738977


Now predicting on finaltest set (0.2 dropout)
Accuracy: 0.9592006661115737
Precision: 0.8331797235023042
Recall: 0.6895499618611747
F1 score: 0.754591


saving LSTM model remote_code_execution.  15:16



