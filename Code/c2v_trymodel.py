import myutils
from datetime import datetime
import sys
import numpy as np
import os
import pickle
from keras.models import load_model
from gensim.models import Word2Vec, KeyedVectors
from keras.preprocessing import sequence
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
import tensorflow as tf
import numpy

def printAndLog(logString,filename):
  print(logString)
  filename.write(logString + '\n')

#trying to activate GPU
tf.config.experimental.list_physical_devices('GPU')

#default mode / type of vulnerability
# command_injection / open_redirect / path_disclosure / remote_code_execution / sql / xsrf / xss
mode = "remote_code_execution"

#get the vulnerability from the command line argument
if (len(sys.argv) > 1):
  mode = sys.argv[1]

# parameters
minCount = 10
c2vIter = 101
c2vVectorSize = 35
stringMode = 'withoutString'

dropout = 0.2
neurons = 140
opt = 'adam'
epochs = 600
batchsize = 128
gpu = 'True'

#modelName = f'LSTM_model_c2v_min{minCount}_iter{c2vIter}_vcsz{c2vVectorSize}_{stringMode}_drop{dropout}_neur{neurons}_opt_{opt}_eps{epochs}_btsz{batchsize}_gpu_{gpu}_{mode}.h5'
#model = load_model('model/LSTM_model_'+mode+'.h5',custom_objects={'f1_loss': myutils.f1_loss, 'f1':myutils.f1})
modelName = 'LSTM_model_c2v_windowLength200_min9_iter101_vcsz10_withoutString_drop0.2_neur200_opt_adam_eps300_btsz128_gpu_True_remote_code_execution.h5'
model = load_model('c2v\\c2vModels\\' + mode + '\\' + modelName,custom_objects={'f1_loss': myutils.f1_loss, 'f1':myutils.f1})
  

with open('data/' + mode + '_dataset_finaltest_X', 'rb') as fp:
  FinaltestX = pickle.load(fp)
with open('data/' + mode + '_dataset_finaltest_Y', 'rb') as fp:
  FinaltestY = pickle.load(fp)

now = datetime.now() # current date and time
nowformat = now.strftime("%H:%M")

#Prepare the data for the LSTM model

X_finaltest =  numpy.array(FinaltestX,dtype=object)
y_finaltest =  numpy.array(FinaltestY)

#in the original collection of data, the 0 and 1 were used the other way round, so now they are switched so that "1" means vulnerable and "0" means clean.
    
for i in range(len(y_finaltest)):
  y_finaltest[i] = 1 - y_finaltest[i]

now = datetime.now() # current date and time
nowformat = now.strftime("%H:%M")
f = open(mode + 'Res.txt','w')
printAndLog(str(len(X_finaltest)) + " samples in the final test set.",f)
  
csum = 0
for y in y_finaltest:
  csum = csum+y

printAndLog("percentage of vulnerable samples: "  + str(int((csum / len(X_finaltest)) * 10000)/100) + "%",f)
printAndLog("absolute amount of vulnerable samples in test set: " + str(csum),f)

#padding sequences on the same length
max_length = 200   
X_finaltest = sequence.pad_sequences(X_finaltest, maxlen=max_length)

yhat_classes = (model.predict(X_finaltest) > 0.5).astype("int32")
#yhat_classes = model.predict(X_finaltest,verbose=0)
#yhat_classes = np.argmax(model.predict(X_finaltest,verbose=0))
#yhat_classes = model.predict_classes(X_finaltest, verbose=0)

accuracy = accuracy_score(y_finaltest, yhat_classes)
precision = precision_score(y_finaltest, yhat_classes)
recall = recall_score(y_finaltest, yhat_classes)
F1Score = f1_score(y_finaltest, yhat_classes)


#f= open(mode + '_stats.txt','w')
printAndLog("Accuracy: " + str(accuracy),f)
#f.write("Accuracy: " + str(accuracy))
printAndLog("Precision: " + str(precision), f)
#f.write("Precision: " + str(precision))
printAndLog("Recall: " + str(recall), f)
#f.write("Recall: " + str(recall))
printAndLog('F1 score: %f' % F1Score, f)
#f.write('F1 score: %F' % F1Score)
printAndLog("\n",f)
f.close()




