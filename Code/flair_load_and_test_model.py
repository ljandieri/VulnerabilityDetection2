from pathlib import Path
import os

from flair.data import Corpus
from flair.datasets import ClassificationCorpus
from flair.embeddings import TransformerDocumentEmbeddings
from flair.models import TextClassifier
from flair.trainers import ModelTrainer
from flair.data import Sentence

import myutils
from myutils import metricCalculator
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

if __name__ == '__main__':

    # for automatically saving results
    auto_trace = True
    trace_file = None

    mode = 'xss'

    label_type = 'vulnerability'
    thisDir = os.getcwd()
    modeDataDir = thisDir + '\\flair\\processedData\\' + mode + '\\'
    trainFileName = mode + '_processed_flair_train'
    validationFileName = mode + '_processed_flair_validation'
    testFileName = mode + '_processed_flair_test'

    ## training parameters
    lr = 5.0e-5
    mBatchSize = 32
    epochs = 10
    modelName = f'Flair_transformer_model_lr{lr}_mbtcsz{mBatchSize}_eps{epochs}_{mode}'
    modelDir = thisDir + '\\flair\\models\\' + mode + '\\' + modelName + '\\'
    modelPath = modelDir + 'final-model.pt'

    # load the model
    classifier = TextClassifier.load(modelPath)

    # load data from appropriate file
    trainData = None
    validationData = None
    testData = None

    X_train = []
    y_train = []
    X_validation = []
    y_validation = []
    X_test = []
    y_test = []


    with open(modeDataDir + trainFileName, encoding='utf-8') as f:
        trainData = f.readlines()
        for line in trainData:
            data = line.split('__label__')[1]
            data = data.split(' ',1)
            thisLabel = int(data[0])
            thisInput = data[1]
            X_train.append(thisInput)
            y_train.append(thisLabel)

    with open(modeDataDir + validationFileName, encoding='utf-8') as f:
        validationData = f.readlines()
        for line in validationData:
            data = line.split('__label__')[1]
            data = data.split(' ',1)
            thisLabel = int(data[0])
            thisInput = data[1]
            X_validation.append(thisInput)
            y_validation.append(thisLabel)

    with open(modeDataDir + testFileName, encoding='utf-8') as f:
        testData = f.readlines()
        for line in testData:
            data = line.split('__label__')[1]
            data = data.split(' ',1)
            thisLabel = int(data[0])
            thisInput = data[1]
            X_test.append(thisInput)
            y_test.append(thisLabel)

    # validate data on train and test set

    if auto_trace:
        traceDir = 'flair\\traces\\' + mode
        if not os.path.isdir(traceDir):
            os.mkdir(traceDir)

        trace_file = open(traceDir + '/' + modelName, 'w')

    lenXTrain = len(X_train)
    lenXVal = len(X_validation)
    lenXTest = len(X_test)

    for dataset in ["train", "test", "finaltest"]:
        print("Now predicting on " + dataset + " set ")

        ## placeholder values for variable declaration
        accuracy = -13
        precision = -13
        recall = -13
        F1Score = -13

        progressDivisor = 1000

        if dataset == "train":
            thisPredictions = []
            for input in X_train:
                thisSentence = Sentence(input)
                classifier.predict(thisSentence)
                thisPrediction = int(thisSentence.labels[0].value)

                thisPredictions.append(thisPrediction)

                # to see progress
                if len(thisPredictions) % progressDivisor == 0:
                    print(f'predicted {len(thisPredictions)}/{lenXTrain} samples for {dataset} dataset')

            accuracy = accuracy_score(y_train, thisPredictions)
            precision = precision_score(y_train, thisPredictions)
            recall = recall_score(y_train, thisPredictions)
            F1Score = f1_score(y_train, thisPredictions)

        if dataset == "test":
            thisPredictions = []
            for input in X_validation:
                thisSentence = Sentence(input)
                classifier.predict(thisSentence)
                thisPrediction = int(thisSentence.labels[0].value)

                thisPredictions.append(thisPrediction)

                # to see progress
                if len(thisPredictions) % progressDivisor == 0:
                    print(f'predicted {len(thisPredictions)}/{lenXVal} samples for {dataset} dataset')
            """
            m2 = metricCalculator(y_validation,thisPredictions)
            m2.generateData()
            accuracy = m2.accuracy
            precision = m2.precision
            recall = m2.recall
            F1Score = m2.F1
            """
            accuracy = accuracy_score(y_validation, thisPredictions)
            precision = precision_score(y_validation, thisPredictions)
            recall = recall_score(y_validation, thisPredictions)
            F1Score = f1_score(y_validation, thisPredictions)
            """"""
        if dataset == "finaltest":
            thisPredictions = []
            for input in X_test:
                thisSentence = Sentence(input)
                classifier.predict(thisSentence)
                thisPrediction = int(thisSentence.labels[0].value)

                thisPredictions.append(thisPrediction)

                # to see progress
                if len(thisPredictions) % progressDivisor == 0:
                    print(f'predicted {len(thisPredictions)}/{lenXTest} samples for {dataset} dataset')

            """
            m3 = metricCalculator(y_test,thisPredictions)
            m3.generateData()
            accuracy = m3.accuracy
            precision = m3.precision
            recall = m3.recall
            F1Score = m3.F1
            """
            accuracy = accuracy_score(y_test, thisPredictions)
            precision = precision_score(y_test, thisPredictions)
            recall = recall_score(y_test, thisPredictions)
            F1Score = f1_score(y_test, thisPredictions)
            """"""
        thisPrint = '\n'.join([
            "Accuracy: " + str(accuracy),
            "Precision: " + str(precision),
            "Recall: " + str(recall),
            'F1 score: %f' % F1Score,
            "\n"
        ])
        print(thisPrint)
        trace_file.write(thisPrint)

if auto_trace:
    trace_file.close()
