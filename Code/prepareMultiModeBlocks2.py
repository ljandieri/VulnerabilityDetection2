import sys
import pickle
import os
import json
from datetime import datetime
import myutils
import random

mode = "sql"
# path_disclosure, command_injection, xsrf,
# get the vulnerability from the command line argument
if (len(sys.argv) > 1):
    mode = sys.argv[1]

progress = 0
count = 0

### paramters for the filtering and creation of samples
#restriction = [20000, 5, 6, 10]  # which samples to filter out
step = 5  # step lenght n in the description
fulllength = 200  # context length m in the description

mode2 = str(step) + "_" + str(fulllength)

thisDir = os.getcwd()
targetRelativePath = '\\separatedBlocks\\' + mode
targetAbsPath = thisDir + targetRelativePath + '/'
if not os.path.exists(thisDir+targetRelativePath):
    os.mkdir(thisDir+targetRelativePath)
#targetFileName = modes + f'_processed_step{step}_length{fulllength}'

targetFileNameTrain = f'{mode}_processed_step{step}_length{fulllength}_train'
targetFileNameValidate = f'{mode}_processed_step{step}_length{fulllength}_validate'
targetFileNameTest = f'{mode}_processed_step{step}_length{fulllength}_test'

targetFileNameTrainLabels = f'{mode}_processed_step{step}_length{fulllength}_train_labels'
targetFileNameValidateLabels = f'{mode}_processed_step{step}_length{fulllength}_validate_labels'
targetFileNameTestLabels = f'{mode}_processed_step{step}_length{fulllength}_test_labels'

data = {}
dataSize = 0

thisDataPath = thisDir + '\\' + 'data/plain_' + mode
with open(thisDataPath, 'r') as infile:
    thisData = json.load(infile)
    dataSize+= len(thisData)
data.update(thisData)
now = datetime.now()  # current date and time
nowformat = now.strftime("%H:%M")
print(f"finished loading data from {mode}. ", nowformat)

allblocks = []

for r in data:
    progress = progress + 1

    for c in data[r]:

        if "files" in data[r][c]:
            #  if len(data[r][c]["files"]) > restriction[3]:
            # too many files
            #    continue

            for f in data[r][c]["files"]:

                #      if len(data[r][c]["files"][f]["changes"]) >= restriction[2]:
                # too many changes in a single file
                #       continue

                if not "source" in data[r][c]["files"][f]:
                    # no sourcecode
                    continue

                if "source" in data[r][c]["files"][f]:
                    sourcecode = data[r][c]["files"][f]["source"]
                    #     if len(sourcecode) > restriction[0]:
                    # sourcecode is too long
                    #       continue

                    allbadparts = []

                    for change in data[r][c]["files"][f]["changes"]:

                        # get the modified or removed parts from each change that happened in the commit
                        badparts = change["badparts"]
                        count = count + len(badparts)

                        #     if len(badparts) > restriction[1]:
                        # too many modifications in one change
                        #       break

                        for bad in badparts:
                            # check if they can be found within the file
                            pos = myutils.findposition(bad, sourcecode)
                            if not -1 in pos:
                                allbadparts.append(bad)

                    #   if (len(allbadparts) > restriction[2]):
                    # too many bad positions in the file
                    #     break

                    if (len(allbadparts) > 0):
                        #   if len(allbadparts) < restriction[2]:
                        # find the positions of all modified parts
                        positions = myutils.findpositions(allbadparts, sourcecode)

                        # get the file split up in samples
                        blocks = myutils.getblocks(sourcecode, positions, step, fulllength)

                        for b in blocks:
                            # each is a tuple of code and label
                            allblocks.append(b)

keys = []
allblockssize = sys.getsizeof(allblocks)
print(f'size of all blocks: {allblockssize}')

print("total length of the sample set: " + str(len(allblocks)))
for i in range(len(allblocks)):
  keys.append(i)
random.shuffle(keys)

cutoff = round(0.7 * len(keys)) #     70% for the training set
cutoff2 = round(0.85 * len(keys)) #   15% for the validation set and 15% for the final test set

keystrain = keys[:cutoff]
keysvalidate = keys[cutoff:cutoff2]
keystest = keys[cutoff2:]

print("cutoff " + str(cutoff))
print("cutoff2 " + str(cutoff2))

TrainX = []
TrainY = []
ValidateX = []
ValidateY = []
TestX = []
TestY = []

print("Creating training dataset... (" + mode + ")")

for k in keystrain:
  block = allblocks[k]
  code = block[0]
  TrainX.append(code)
  TrainY.append(block[1]) #append the label to the Y (dependent variable)

print("Creating validation dataset...")
for k in keysvalidate:
  block = allblocks[k]
  code = block[0]
  ValidateX.append(code)
  ValidateY.append(block[1]) #append the label to the Y (dependent variable)

print("Creating finaltest dataset...")
for k in keystest:
  block = allblocks[k]
  code = block[0]
  TestX.append(code)
  TestY.append(block[1]) #append the label to the Y (dependent variable)

print("Train length: " + str(len(TrainX)))
print("Test length: " + str(len(ValidateX)))
print("Finaltesting length: " + str(len(TestX)))
trainLength = len(TrainX)
trainSplit = []
trainSplitLabels = []
slices = 7
for i in range(slices):
    botIndex = int((trainLength * i) / slices)
    topIndex = int((trainLength * (i+1))/slices)
    trainSplit.append(TrainX[botIndex:topIndex])
    trainSplitLabels.append(TrainY[botIndex:topIndex])

for i in range(slices):
    with open(targetAbsPath + targetFileNameTrain + '_' + str(i + 1), 'wb') as fp:
        pickle.dump(trainSplit[i], fp)

    with open(targetAbsPath + targetFileNameTrainLabels + '_' + str(i + 1), 'wb') as fp:
        pickle.dump(trainSplitLabels[i], fp)


with open(targetAbsPath + targetFileNameTest, 'wb') as fp:
    pickle.dump(TestX, fp)

with open(targetAbsPath + targetFileNameValidate, 'wb') as fp:
     pickle.dump(ValidateX, fp)

with open(targetAbsPath + targetFileNameValidateLabels, 'wb') as fp:
  pickle.dump(ValidateY, fp)

with open(targetAbsPath + targetFileNameTestLabels, 'wb') as fp:
  pickle.dump(TestY, fp)

print(f'all blocks successfully saved')
