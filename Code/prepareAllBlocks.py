import sys
import pickle
import os
import json
from datetime import datetime
import myutils

mode = "remote_code_execution"

# get the vulnerability from the command line argument
if (len(sys.argv) > 1):
    mode = sys.argv[1]

progress = 0
count = 0

### paramters for the filtering and creation of samples
#restriction = [20000, 5, 6, 10]  # which samples to filter out
step = 5  # step lenght n in the description
fulllength = 200  # context length m in the description

mode2 = str(step) + "_" + str(fulllength)

thisDir = os.getcwd()
targetRelativePath = '\\dataProcessed\\'
targetAbsPath = thisDir + targetRelativePath
targetFileName = mode + '_processed'

if os.path.exists(targetAbsPath + targetFileName):
    print(f'processed {mode} data already exists: \n{targetAbsPath + targetFileName}')
    sys.exit(0)

# load data
thisDataPath = thisDir + '\\' + 'data/plain_' + mode
with open(thisDataPath, 'r') as infile:
    data = json.load(infile)

now = datetime.now()  # current date and time
nowformat = now.strftime("%H:%M")
print("finished loading data. ", nowformat)

allblocks = []

for r in data:
    progress = progress + 1

    for c in data[r]:

        if "files" in data[r][c]:
            #  if len(data[r][c]["files"]) > restriction[3]:
            # too many files
            #    continue

            for f in data[r][c]["files"]:

                #      if len(data[r][c]["files"][f]["changes"]) >= restriction[2]:
                # too many changes in a single file
                #       continue

                if not "source" in data[r][c]["files"][f]:
                    # no sourcecode
                    continue

                if "source" in data[r][c]["files"][f]:
                    sourcecode = data[r][c]["files"][f]["source"]
                    #     if len(sourcecode) > restriction[0]:
                    # sourcecode is too long
                    #       continue

                    allbadparts = []

                    for change in data[r][c]["files"][f]["changes"]:

                        # get the modified or removed parts from each change that happened in the commit
                        badparts = change["badparts"]
                        count = count + len(badparts)

                        #     if len(badparts) > restriction[1]:
                        # too many modifications in one change
                        #       break

                        for bad in badparts:
                            # check if they can be found within the file
                            pos = myutils.findposition(bad, sourcecode)
                            if not -1 in pos:
                                allbadparts.append(bad)

                    #   if (len(allbadparts) > restriction[2]):
                    # too many bad positions in the file
                    #     break

                    if (len(allbadparts) > 0):
                        #   if len(allbadparts) < restriction[2]:
                        # find the positions of all modified parts
                        positions = myutils.findpositions(allbadparts, sourcecode)

                        # get the file split up in samples
                        blocks = myutils.getblocks(sourcecode, positions, step, fulllength)

                        for b in blocks:
                            # each is a tuple of code and label
                            allblocks.append(b)

allblockssize = sys.getsizeof(allblocks)
print(f'size of all blocks: {allblockssize}')

with open(targetAbsPath + targetFileName, 'wb') as fp:
  pickle.dump(allblocks, fp)

print(f'all blocks successfully saved at {targetAbsPath+targetFileName}.')
